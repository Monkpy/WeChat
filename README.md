# WeChat
获取搜狗微信公众号文章

通过fiddler抓包获取到可以返回SUV的链接，进行拼接urlencode()编译，获取返回后的cookie中的SUV（可能涉及翻页问题，在翻页时会调用此链接）；

SNUID： 用于标记处理访问次数限制，开始使用本机IP获取，后期在请求'真'URL时判断返回数据是否乱码，来使用IP代理重新调用cookie获取页面，从而重新请求数据，次标识随便请求一页搜狗微信的页面就可以获得（此处用的时列表页，也可以使用本机IP重新获取，此处考虑到封IP直接使用IP来获取），可以根据SNUID来创建一个cookie池，来解决此问题；

步骤一：
首先抓包一个指向性链接，https://pb.sogou.com/pv.gif?开头的指向列表链接，添加无cookie的请求头即可获取返回的cookie中的SUV

步骤二：
携带无cookie的请求头请求列表页链接，获取返回后的cookie中的SNUID，此SNUID为重点，必须获取（可以根据SNUID创建cookie池）；

步骤三：
首次获取的列表页的dn9连接，是一个假连接，需要调用已给js处理拼接，js处理的时k与h的值，直接重写即可；

步骤四：
拼接好的URL是一个可跳转的'真'连接，请求此连接返回的内容中包含了真是连接，但是请求此连接的时候需要添加cookie，且cookie中必须携带SNUID，SNUID是判断请求次数的标识，如无法正常访问更改cookie即可（创建cookie池的必要性<也可以像本文一样更换IP循环调取>）

步骤五：
获取到真实链接后直接请求即可

注：未涉及翻页后期再更新...
